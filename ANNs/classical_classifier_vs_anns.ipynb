{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why do we need artificial neural networks?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train a `SGDClassifier` and an artificial neural network with a sequential method in `keras`. In both cases a versicolor detector (binary classifier model) will be constructed using the classical dataset `load_iris` from sklearn and we will see that in some sense the neural network help us to avoid feature engineearing."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some functions for preprocessing the dataset are in `prepross_iris_data.py` file. It is recommended go to the function's documentation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin focussing only on petal data (just the last columns in iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from prepross_iris_data import *\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "X_pet = only_sepal_or_petal(X, kind='petal')\n",
    "y_ver = label_binary(y, kind='versicolor')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we are focussed only on petal information and the task is just create a versicolor detector. We will create a figure in which you will see that the versicolor class is not linearly separable."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'Versicolor_class.png'> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `SGDClassifier` with and without feature engineearing over the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For simplicity, the following score is just on the train set.\n",
      "Score:  0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "classical_clf = SGDClassifier()\n",
    "classical_clf.fit(X_pet, y_ver) # without feature engineearing\n",
    "print('For simplicity, the following score is just on the train set.')\n",
    "print('Score: ', classical_clf.score(X_pet, y_ver))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can help the classifier with the practice of feature engineearing strategy in the following way:\n",
    "\n",
    "1) Traslate the data using the versicolor means of length and width respectively.\n",
    "\n",
    "2) Create a new feature taking the square of the data in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_mean, w_mean = means_sepal_or_petal(X, kind='petal') # length mean and width mean\n",
    "X_pet_tras = traslate_data(X_pet, l_mean, w_mean)\n",
    "X_pet_tras_squared = np.square(X_pet_tras) # take data squared is considered feature engineearing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following figure shows the versicolor new representation is now a little bit near of being linearly separable"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'Versicolor_separable.png'> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we use again a `SGDClassifier` after feature engineearing excecuted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For simplicity, the following score is just on the train set.\n",
      "Score:  0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "classical_clf = SGDClassifier()\n",
    "classical_clf.fit(X_pet_tras_squared, y_ver) # with feature engineearing\n",
    "print('For simplicity, the following score is just on the train set.')\n",
    "print('Score: ', classical_clf.score(X_pet_tras_squared, y_ver))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the classifier is better now."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial neural network without feature engineearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3034 - accuracy: 0.9000\n",
      "ANN's score:  0.8999999761581421\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "model_pet = keras.models.Sequential()\n",
    "model_pet.add(keras.layers.Flatten(input_shape=[2]))\n",
    "model_pet.add(keras.layers.Dense(32, activation='relu'))\n",
    "model_pet.add(keras.layers.Dense(32, activation='relu'))\n",
    "model_pet.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_pet.compile(loss=\"BinaryCrossentropy\",\n",
    "                optimizer='sgd',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "model_pet.fit(X_pet_tras, y_ver, epochs=100, verbose=0)\n",
    "\n",
    "# the use of evaluate method should be over a test_set, but here it is used X_pet_tras\n",
    "print(\"ANN's score: \", model_pet.evaluate(X_pet_tras, y_ver)[1]) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy show us that the artificial neural network's success without feature engineearing (that is, take squares) is better than the SGDClassifier success without feature engineearing. In conclusion, We have seen a case of binary classifiers in which under the same conditions (without feature engineearing) the artificial neural network has beaten the classical model.\n",
    "\n",
    "In the following figure you can see how the artificial neural network detects versicolor zone, even with not linearly separable data. Also, it is important recognize that we could work a lot to improve the power of generalization but it wasn't the purpose of this notebook. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='Versicolor_ann.png'>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
